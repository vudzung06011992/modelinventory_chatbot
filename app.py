import streamlit as st
import os
from ultis import *
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.sql_database import SQLDatabase
from typing import TypedDict, Annotated, List
import copy
query_prompt_template = hub.pull("langchain-ai/sql-query-system-prompt")
from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool
assert len(query_prompt_template.messages) == 1
import time 
import copy
import json
import warnings
from langchain_core.prompts import PromptTemplate
warnings.filterwarnings("ignore")

db = SQLDatabase.from_uri(SUPABASE_URI)

execute_query_tool = QuerySQLDatabaseTool(db=db)
print("k·∫øt n·ªëi db th√†nh c√¥ng")
# C·∫•u h√¨nh LLM
from langchain.chat_models import init_chat_model
claude = init_chat_model("claude-3-5-sonnet-20241022")
openai = init_chat_model("gpt-4")

# T·∫°o b·ªô nh·ªõ h·ªôi tho·∫°i
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True, k = 5)

# H√†m truy v·∫•n d·ªØ li·ªáu t·ª´ Supabase
from langchain.schema import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from ultis import FULL_DES_JSON, TERM_DES_JSON, DB_SCHEMA_DESCRIPTION   

def clarify_question(query, chat_history, llm_model):

    def remove_curly_braces(text):
        return text.replace("{", "").replace("}", "")
    
    context = "\n".join([f"C√¢u h·ªèi User: {chat['user']} ==> Bot hi·ªÉu y√™u c·∫ßu nh∆∞ sau: {remove_curly_braces(chat['bot'])}" \
                         for chat in chat_history])
    print("========== L·ªäCH S·ª¨ CONTEXT: ========= \n", context)
    system = DB_SCHEMA_DESCRIPTION \
    + """You are a DB assistant. D·ª±a tr√™n h·ªôi tho·∫°i tr∆∞·ªõc: """ + context \
    + """V·ªõi c√¢u h·ªèi hi·ªán t·∫°i c·ªßa User: {question}. """ \
    + """ Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
    - H√£y di·ªÖn gi·∫£i r√µ r√†ng, ch√≠nh x√°c y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng hi·ªán t·∫°i (H√ÉY NH·ªö R·∫∞NG: nh·ªØng g√¨ b·∫°n kh√¥ng ch·∫Øc ch·∫Øn, ƒë·ª´ng cho v√†o, ƒë·ª´ng di·ªÖn gi·∫£i, Kh√¥ng ghi c·ª• th·ªÉ t√™n tr∆∞·ªùng d·ªØ li·ªáu, kh√¥ng t√≥m t·∫Øt)
    - C√°c b·∫£ng d·ªØ li·ªáu c·∫ßn d√πng (b·∫Øt bu·ªôc ph·∫£i c√≥ GSTD_Model Development). N·∫øu c√≥ ƒë·ªÅ c·∫≠p t·ªõi ph√¢n lo·∫°i theo lo·∫°i 1, lo·∫°i 2 hay lo·∫°i 3 th√¨ ph·∫£i th√™m b·∫£ng GSTD_Model Validation v√†o.  N·∫øu ƒë·ªÅ c·∫≠p ph√¢n lo·∫°i theo Cao, Th·∫•p, Trung b√¨nh th√¨ th√™m b·∫£ng GSTD_Model Risk Rating v√†o.
    K·∫øt qu·∫£ c·∫ßn tr·∫£ ra l√† json c√≥ key l√† clarified_question v√† tables."""

    human = "{question}"
    prompt = ChatPromptTemplate.from_messages([
                                                                                ("system", system), ("human", human)
                                                                            ])

    chain = prompt | llm_model
    tmp = chain.invoke(
        {
            "question": query
        })  

    return tmp.content

# Giao di·ªán Streamlit
st.title("Model-Inventory AI Chatbot")
st.write("Nh·∫≠p c√¢u h·ªèi v·ªÅ d·ªØ li·ªáu trong Supabase Database:")

# L∆∞u h·ªôi tho·∫°i trong session
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Nh·∫≠p c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
user_input = st.text_input("C√¢u h·ªèi c·ªßa b·∫°n?")

if st.button("Send"):
    if user_input:
        start_time = time.time()
        # L∆∞u c√¢u h·ªèi v√†o b·ªô nh·ªõ
        memory.save_context({"input": user_input}, {"output": ""})

        ################ I. Th·ª±c thi query SQL t·ª´ AI v·ªõi ng·ªØ c·∫£nh h·ªôi tho·∫°i ################
        result_1 = clarify_question(user_input, st.session_state.chat_history, claude)
        print("****** Result_1: ", result_1)
        st.write("****** C√¢u h·ªèi ƒë∆∞·ª£c l√†m r√µ ******: ", result_1)

        # t√°ch th√¥ng tin t·ª´ k·∫øt qu·∫£ tr·∫£ v·ªÅ
        result_1 = json.loads(result_1)
        clarified_question = result_1["clarified_question"]
        tables_to_extract = result_1["tables"]

        ################ II. Extract th√¥ng tin c·∫ßn thi·∫øt ################
        
        def extract_tables_from_json(json_data, tables_to_extract):
            """
            H√†m tr√≠ch xu·∫•t th√¥ng tin t·ª´ JSON d·ª±a tr√™n danh s√°ch c√°c b·∫£ng cho tr∆∞·ªõc.
            
            Args:
                json_data (str or dict): D·ªØ li·ªáu JSON d∆∞·ªõi d·∫°ng chu·ªói ho·∫∑c dictionary.
                tables_to_extract (list): Danh s√°ch c√°c b·∫£ng c·∫ßn tr√≠ch xu·∫•t.
            Returns:
                dict: Dictionary ch·ª©a d·ªØ li·ªáu c·ªßa c√°c b·∫£ng ƒë∆∞·ª£c y√™u c·∫ßu.
            """
            # N·∫øu ƒë·∫ßu v√†o l√† chu·ªói JSON, chuy·ªÉn ƒë·ªïi th√†nh dictionary
            if isinstance(json_data, str):
                json_data = json.loads(json_data)
            # L·ªçc c√°c b·∫£ng theo danh s√°ch y√™u c·∫ßu
            extracted_data = {table: json_data[table] for table in tables_to_extract if table in json_data}
            return extracted_data

        info_dict = {
            "question": clarified_question,
            "input": extract_tables_from_json(FULL_DES_JSON, tables_to_extract)    
        }

        ################# III: x√¢y d·ª±ng c√¢u l·ªánh query ################
        from langchain_community.agent_toolkits import SQLDatabaseToolkit
        from typing_extensions import Annotated
        toolkit = SQLDatabaseToolkit(db=db, llm=claude)
        tools = toolkit.get_tools()

        from langgraph.prebuilt import create_react_agent

        def write_query(llm_model, info_dict):

            prompt = PromptTemplate.from_template(
                (TERM_DES_JSON + """
                    B·∫°n nh·∫≠n ƒë∆∞·ª£c th√¥ng tin c√°c b·∫£ng d·ªØ li·ªáu, c√°c tr∆∞·ªùng d·ªØ li·ªáu li√™n quan l√† {input}. 
                    B·∫°n h√£y x√¢y d·ª±ng c√¢u l·ªánh query {dialect} cho ph√π h·ª£p v·ªõi y√™u c·∫ßu ng∆∞·ªùi d√πng. 
                    You have access to the following tools:{tools}

                    L∆∞u √Ω:
                    - T√äN C√ÅC B·∫¢NG, C·ªòT PH·∫¢I ƒê·ªÇ TRONG ""
                    - Vi·ªác mapping c√°c b·∫£ng d·ª±a tr√™n tr∆∞·ªùng DevelopmentID. Tr∆∞·ªùng DevelopmenID kh√¥ng ph·∫£i l√† ModelID. Kh√¥ng ƒë∆∞·ª£c d√πng DevelopmenID = ModelID
                    - C√¢u l·ªánh ph·∫£i tu√¢n th·ªß nguy√™n t·∫Øc c·ªßa {dialect} trong Supabase.
                    - C√°c TR∆Ø·ªúNG DATE (t√™n tr∆∞·ªùng c√≥ ch·ªØ date) ph·∫£i ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi v·ªÅ int v·ªõi gi√° tr·ªã kh√¥ng null, r·ªìi m·ªõi s·ª≠ d·ª•ng. L∆∞u √Ω: c√°c tr∆∞·ªùng n√†y c√≥ th·ªÉ t·ªìn t·∫°i gi√° tr·ªã NULL ho·∫∑c missing.
                    - B·∫°n ph·∫£i r√† so√°t c√¢u h·ªèi ng∆∞·ªùi d√πng ƒë·ªÉ ƒë·∫£m b·∫£o c√¢u l·ªánh tr·∫£ v·ªÅ k·∫øt qu·∫£ ch√≠nh x√°c.
                    - ƒê·ª´ng t·ª± th√™m ƒëi·ªÅu ki·ªán where m√† ng∆∞·ªùi d√πng kh√¥ng c·∫ßn
                    - Kh√¥ng th√™m k√Ω t·ª± \n, \ kh√¥ng c·∫ßn thi·∫øt.

                    B·∫°n ch·ªâ ƒë∆∞·ª£c tr·∫£ ra c√¢u l·ªánh query (kh√¥ng th√™m b·∫•t k·ª≥ th√¥ng tin n√†o kh√°c) m√† ph·∫£i ch·∫°y ƒë∆∞·ª£c. Only return the Query, no explanation, no description.

                    Use the following format:
                    Question: the input question you must answer
                    Thought: you should always think about what to do
                    Action: the action to take, should be one of {tools}
                    Action Input: the input to the action
                    Observation: the result of the action
                    ... (this Thought/Action/Action Input/Observation can repeat N times)
                    Thought: I now know the final answer
                    Final Answer: the final answer to the original input question

                    Begin!
                    Question: {question}
                """)
            )

            # Format prompt v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø
            formatted_prompt = prompt.format(
                dialect="PostgreSQL",
                question=info_dict["question"],
                input=info_dict["input"],
                tools= """["QuerySQLDatabaseTool", "InfoSQLDatabaseTool", "ListSQLDatabaseTool", "QuerySQLCheckerTool"]"""
            )

            # üõ† T·∫°o Agent Executor (D√πng Prompt ƒê√É FORMAT)
            agent_executor = create_react_agent(llm_model, tools, prompt=formatted_prompt)
            answer = agent_executor.invoke({"messages": [{"role": "user", "content": info_dict["question"]}]})

            def extract_sql_from_final_answer(text):
                """Tr√≠ch xu·∫•t c√¢u SQL t·ª´ n·ªôi dung ch·ª©a 'Final Answer:'"""
                keyword = "Final Answer:"
                if keyword in text:
                    return text.split(keyword, 1)[1].strip()
                return text

            return {"query": extract_sql_from_final_answer(answer["messages"][1].content)}
        
        result_3 = write_query(claude, info_dict)
        print("******C√¢u l·ªánh l√† :******", result_3["query"])
        st.write("******C√¢u l·ªánh l√†: ******", result_3["query"])

        # IV. Th·ª±c thi c√¢u l·ªánh query
        
        def execute_query(state):
            """Execute SQL query."""
            
            return {"result": execute_query_tool.invoke(state["query"])}

        result_4 = execute_query(result_3)
        st.write("K·∫øt qu·∫£ th·ª±c thi c√¢u l·ªánh : ", result_4["result"])

        # V. Tr·∫£ l·ªùi
        def generate_answer(state, model):
            """Answer question using retrieved information as context."""
            prompt = (
                """
                Given the following user question, corresponding query, 
                and db retrieval result, answer the user question.\n\n
                Question: {}

                SQL Result: {}
                
                Tr√¨nh b√†y ƒë·∫πp, b·ªè c√°c k√Ω t·ª± \n ƒëi
                """.format(state["question"], state["result"])
            )
            response = model.invoke(prompt)
            return response.content
        
        result_5 = generate_answer({"question":clarified_question, "result": result_4 }, openai)
        st.write("******K·∫øt qu·∫£ tr·∫£ l·ªùi : ******", result_5)

    # VI. Hi·ªÉn th·ªã:
    def remove_newlines(text):
        return text.replace("\n", "")

    response_text = "1. C√¢u h·ªèi l√†m r√µ: " + clarified_question +  "----" +  "\n 2. C√¢u l·ªánh query: " + result_3["query"] +  "----" +  "\n 3. K·∫øt qu·∫£:  " + str(result_5)
    # response_text = remove_newlines(response_text)
    st.write(response_text, "\n 4. Th·ªùi gian th·ª±c thi: ", time.time() - start_time)
    
    def summarize_query(db_query, model):
        """m√¥ t·∫£ c√°c ƒëi·ªÅu ki·ªán where trong c√¢u l·ªánh"""
        prompt = (
            """
            D·ª±a v√†o c√¢u query, h√£y m√¥ t·∫£ ng·∫Øn g·ªçn nh∆∞ng v·∫´n ƒë·ªß c√°c √Ω ph·∫°m vi l·∫•y d·ªØ li·ªáu (c√°c ƒëi·ªÅu ki·ªán where)
            Query: {}            

            """.format(db_query)
        )
        response = model.invoke(prompt)
        return response.content
 
    summarized_where_query = summarize_query(result_3["query"], openai)
    st.session_state.chat_history.append({"user": user_input, \
                                                                "bot": clarified_question + ". T·ª´ ƒë√≥, C√°ch Bot th·ª±c hi·ªán l√† : " + str(summarized_where_query)})

# Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i
st.subheader(" L·ªãch s·ª≠ h·ªôi tho·∫°i ")
for chat in st.session_state.chat_history:
    st.write(f"**B·∫°n:** {chat['user']}")
    st.write(f"**Bot:** {chat['bot']}")
